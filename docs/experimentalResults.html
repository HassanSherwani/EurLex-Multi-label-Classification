<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title></title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #0000ff; } /* Keyword */
code > span.ch { color: #008080; } /* Char */
code > span.st { color: #008080; } /* String */
code > span.co { color: #008000; } /* Comment */
code > span.ot { color: #ff4000; } /* Other */
code > span.al { color: #ff0000; } /* Alert */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #008000; font-weight: bold; } /* Warning */
code > span.cn { } /* Constant */
code > span.sc { color: #008080; } /* SpecialChar */
code > span.vs { color: #008080; } /* VerbatimString */
code > span.ss { color: #008080; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { } /* Variable */
code > span.cf { color: #0000ff; } /* ControlFlow */
code > span.op { } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #ff4000; } /* Preprocessor */
code > span.do { color: #008000; } /* Documentation */
code > span.an { color: #008000; } /* Annotation */
code > span.cv { color: #008000; } /* CommentVar */
code > span.at { } /* Attribute */
code > span.in { color: #008000; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3,h4,h5,h6",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = false;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">EurLex classification</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="multilabel_classification_intro.html">Multi-label classification</a>
</li>
<li>
  <a href="exploratory_analysis.html">Exploratory Analysis</a>
</li>
<li>
  <a href="experimentalResults.html">Classification</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(kableExtra)</code></pre></div>
<div id="classification-task" class="section level2">
<h2>Classification task</h2>
<p>The EUR-Lex dataset contains 25K documents, which makes it impossible to train a classifier over the whole dataset. We divided the dataset into 24 subsets, each subset contains the same number of documents, we trained the classifiers over the subsets. The final evaluations results will be the average seperatly reported results for each subset. The dataset has around 7000 labels, an older version had only 4000 labels. To observe the effect of including a large number of labels on the classification task in general, we compared the predective performance of the models when trained on a dataset with 7000 labels and when trained on a dataset with a reduced number of labels.</p>
<div id="classification-models" class="section level4">
<h4><span class="sub-sub-header">Classification Models</span></h4>
<p>We use three methods to transform the problem of multi-label classification task into a conventional multi-class classification task: binary relevance, Label Powerset, classifier chain. After transforming the classification problem, We trained three different classification models: Random Forest, k nearest neighbors, XGboosted trees.</p>
<table class="kable_wrapper table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<td>
<table>
<thead>
<tr>
<th style="text-align:left;">
classifier Models
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
K nearest neighbours
</td>
</tr>
<tr>
<td style="text-align:left;">
Random Forest
</td>
</tr>
<tr>
<td style="text-align:left;">
XGboost
</td>
</tr>
</tbody>
</table>
</td>
<td>
<table>
<thead>
<tr>
<th style="text-align:left;">
Transformation methods
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Binary relevance
</td>
</tr>
<tr>
<td style="text-align:left;">
Classifier chain
</td>
</tr>
<tr>
<td style="text-align:left;">
Label powerset
</td>
</tr>
</tbody>
</table>
</td>
</tr>
</tbody>
</table>
We trained nine classifaction models and compared the performance of the classifiers to produce the model that best fits the dataset and to choose the type of features to yield the best predictive performance. The following table shows the nine classifier models :
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<td style="text-align:left;">
KNN-Label Powerset
</td>
<td style="text-align:left;">
RF-Label Powerset
</td>
<td style="text-align:left;">
XGboost-Label Powerset
</td>
</tr>
</tbody>
</table>
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<td style="text-align:left;">
KNN-Binary Relevance
</td>
<td style="text-align:left;">
RF-Binary Relevance
</td>
<td style="text-align:left;">
XGboost-Binary Relevance
</td>
</tr>
</tbody>
</table>
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<td style="text-align:left;">
KNN-Classifier Chain
</td>
<td style="text-align:left;">
RF-Classifier Chain
</td>
<td style="text-align:left;">
XGboost-Classifier Chain
</td>
</tr>
</tbody>
</table>
</div>
<div id="experimental-settings" class="section level3">
<h3><span class="sub-sub-header">Experimental settings</span></h3>
As mentioned earlier, the 25K documents dataset was split into 24 subsets, and the previously mentioned classification models were trained separately in order to compare the performance of these different classifiers.Each subset was split randomly into two disjointly subsets one for training and the other for testing, with the following proportions ( 65% used for training and 35% used for testing). We reported the results of the different models under different settings, we wanted to explore the performance of the classifiers with two types of features, with two languages and with a different number of labels. The following table demonstrates the experimental settings:
<table class="kable_wrapper table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<td>
<table>
<thead>
<tr>
<th style="text-align:left;">
Language
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
English
</td>
</tr>
<tr>
<td style="text-align:left;">
German
</td>
</tr>
</tbody>
</table>
</td>
<td>
<table>
<thead>
<tr>
<th style="text-align:left;">
Features
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
TFIDF
</td>
</tr>
<tr>
<td style="text-align:left;">
incidence
</td>
</tr>
</tbody>
</table>
</td>
<td>
<table>
<thead>
<tr>
<th style="text-align:left;">
Number of Labels
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
7000
</td>
</tr>
<tr>
<td style="text-align:left;">
4000
</td>
</tr>
</tbody>
</table>
</td>
</tr>
</tbody>
</table>
<p>The following code shows the funcitons used for classification, we use <a href="https://cran.r-project.org/web/packages/utiml/index.html"><em>utiml</em></a> package. To split the dataset into training and testing dataset we use the function <a href="https://www.rdocumentation.org/packages/utiml/versions/0.1.4/topics/create_holdout_partition">create_holdout_partition()</a>.The example code is showen for <strong>binary relevace</strong> method. We simply change the method used into one of the following methods: <a href="https://rdrr.io/cran/utiml/man/lp.html">lp()</a> Label Powerset, <a href="https://rdrr.io/cran/utiml/man/br.html">br()</a> Binary Relevance, <a href="https://rdrr.io/cran/utiml/man/cc.html">cc()</a> Classifier Chain we had to destroy the model after exporting the performance results to avoid any problematics with memory capacity using the function <strong>rm()</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(mldr)
<span class="kw">library</span>(utiml)

train_ratio &lt;-<span class="st"> </span><span class="fl">0.65</span>
test_ratio &lt;-<span class="st"> </span><span class="fl">0.35</span>
iteration &lt;-<span class="st"> </span><span class="dv">24</span>

<span class="cf">for</span>(index <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>iteration){

  ds &lt;-<span class="st"> </span><span class="kw">mldr</span>(<span class="kw">paste</span>(generic_name,index,<span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">remove_skewness_labels</span>(<span class="dv">1</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">remove_attributes</span>(<span class="st">&quot;...&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">remove_unique_attributes</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">remove_unlabeled_instances</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">create_holdout_partition</span>(<span class="kw">c</span>(<span class="dt">train=</span>train_ratio, <span class="dt">test=</span>test_ratio))
  
  ## KNN - K nearest neighbour
  brmodel1 &lt;-<span class="st"> </span><span class="kw">br</span>(ds<span class="op">$</span>train, <span class="st">&quot;KNN&quot;</span>)
  prediction1 &lt;-<span class="st"> </span><span class="kw">predict</span>(brmodel1, ds<span class="op">$</span>test)
  temp_knn &lt;-<span class="st"> </span><span class="kw">multilabel_evaluate</span>(ds<span class="op">$</span>test, prediction1, <span class="st">&quot;bipartition&quot;</span>)

  ##remove model of memory
  <span class="kw">rm</span>(brmodel1)
  <span class="kw">rm</span>(prediction1)
  
  ## RF - Random Forest
  brmodel2 &lt;-<span class="st"> </span><span class="kw">br</span>(ds<span class="op">$</span>train, <span class="st">&quot;RF&quot;</span>)
  prediction2 &lt;-<span class="st"> </span><span class="kw">predict</span>(brmodel2, ds<span class="op">$</span>test)
  temp_rf &lt;-<span class="st"> </span><span class="kw">multilabel_evaluate</span>(ds<span class="op">$</span>test, prediction2, <span class="st">&quot;bipartition&quot;</span>)

  <span class="kw">rm</span>(brmodel2)
  <span class="kw">rm</span>(prediction2)

  ## XGB - eXtreme Gradient Boosting
  brmodel3 &lt;-<span class="st"> </span><span class="kw">br</span>(ds<span class="op">$</span>train, <span class="st">&quot;XGB&quot;</span>)
  prediction3 &lt;-<span class="st"> </span><span class="kw">predict</span>(brmodel3, ds<span class="op">$</span>test)
  temp_xgb &lt;-<span class="st"> </span><span class="kw">multilabel_evaluate</span>(ds<span class="op">$</span>test, prediction3, <span class="st">&quot;bipartition&quot;</span>)

  <span class="kw">rm</span>(brmodel3)
  <span class="kw">rm</span>(prediction3)
  <span class="cf">if</span>(index<span class="op">==</span><span class="dv">1</span>){
  knn &lt;-<span class="st"> </span>temp_knn
  rf &lt;-<span class="st"> </span>temp_rf
  xgb &lt;-<span class="st"> </span>temp_xgb
  }<span class="cf">else</span>{
  knn &lt;-<span class="st"> </span><span class="kw">cbind</span>(knn,temp_knn)
  rf &lt;-<span class="st"> </span><span class="kw">cbind</span>(rf,temp_rf)
  xgb &lt;-<span class="st"> </span><span class="kw">cbind</span>(xgb, temp_xgb)
  }</code></pre></div>
<div id="plotting-graphs-functions" class="section level4">
<h4><span class="sub-sub-header">Plotting Graphs Functions</span></h4>
<p>we used the <strong>ggplot2</strong> package to display the evaluation metrics graphs. The following function <strong>ggplot()</strong> for plotting the graphs and <strong>ggsave()</strong> to save the last plotted graph.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(performance)<span class="op">+</span><span class="kw">ylab</span>(<span class="st">&quot;value&quot;</span>)<span class="op">+</span><span class="kw">xlab</span>(<span class="st">&quot;model&quot;</span>)<span class="op">+</span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.25</span>, <span class="fl">0.5</span>,<span class="fl">0.75</span>, <span class="fl">1.0</span>))<span class="op">+</span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span>performance<span class="op">$</span>model,<span class="dt">y=</span>performance<span class="op">$</span>value,<span class="dt">color=</span>metric),<span class="dt">size=</span><span class="dv">5</span>,<span class="dt">alpha=</span><span class="fl">0.7</span>)<span class="op">+</span><span class="kw">facet_grid</span>(performance<span class="op">$</span>metric<span class="op">~</span>.)<span class="op">+</span><span class="kw">coord_flip</span>()<span class="op">+</span><span class="kw">theme_bw</span>()
<span class="kw">ggsave</span>(<span class="st">&quot;/multilabelclassification/graphs/cc_EN_tfidf1.png&quot;</span>,<span class="dt">width =</span> <span class="dv">8</span>, <span class="dt">height =</span> <span class="dv">7</span>, <span class="dt">dpi =</span> <span class="dv">400</span>)
<span class="kw">ggplot</span>(performance)<span class="op">+</span><span class="kw">geom_tile</span>(<span class="kw">aes</span>(<span class="dt">x=</span>model,<span class="dt">y=</span>metric,<span class="dt">fill=</span>value),<span class="dt">color=</span><span class="st">&quot;black&quot;</span>)<span class="op">+</span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">x=</span>model,<span class="dt">y=</span>metric,<span class="dt">label=</span><span class="kw">round</span>(value,<span class="dv">3</span>)),<span class="dt">color=</span><span class="st">&quot;black&quot;</span>)<span class="op">+</span><span class="kw">scale_fill_distiller</span>(<span class="dt">palette =</span> <span class="st">&quot;Spectral&quot;</span>)
<span class="kw">ggsave</span>(<span class="st">&quot;/multilabelclassification/graphs/cc_EN_tfidf2.png&quot;</span>,<span class="dt">width =</span> <span class="dv">6</span>, <span class="dt">height =</span> <span class="dv">4</span>, <span class="dt">dpi =</span> <span class="dv">400</span>)</code></pre></div>
</div>
</div>
<div id="experimental-resutls" class="section level3">
<h3><span class="sub-header">Experimental Resutls</span></h3>
<p>We tested the nine models over two languages (English and German) and with two types of features (TF-IDF and the terms incidence). Across all the experiments, we inferred that combining the label powerset transformation method with the random forest classifier produced the highest accuracy around (30%), however, combining the label power set with the XGBoost classifier resulted in the lowest accuracy about (5%). We observed higher accuracy rates over all the nine trained classifiers when we used TF-IDFs as the instances features. TF-IDFs are more powerful representative features than simply using the terms incidence. Despite the deteriorated performance of the XGBoost-Label powerset classifier, applying each of the Binary Relevance and the classifier chain methods with the XGBoost classifier produced the second best accuracy.</p>
<div id="language-english-feature-tf-idf-nr-of-labels-7000-labels" class="section level4 tabset tabset-fade">
<h4><span class="sub-sub-header">Language: English, Feature: TF-IDF, Nr of Labels: 7000 Labels</span></h4>
<div id="label-powerset" class="section level5">
<h5>Label Powerset</h5>
<p>we compared the three models where the label sets considered as classes. Random Forest achieved the highest accuracy compared to the XGBoost model which significantly achieved the lowest accuracy.</p>
<div class="figure">
<img src="Figs/lp_EN_tfidf1.png" />

</div>
<div class="figure">
<img src="Figs/lp_EN_tfidf2.png" />

</div>
</div>
<div id="binary-relevance" class="section level5">
<h5>Binary Relevance</h5>
<p>We compared the three models where the labels are assumed to be independent. The three models performed almost similiarly.</p>
<div class="figure">
<img src="Figs/br_EN_tfidf1.png" />

</div>
<div class="figure">
<img src="Figs/br_EN_tfidf2.png" />

</div>
</div>
<div id="classifier-chains" class="section level5">
<h5>Classifier Chains</h5>
<p>we compared the three models where we applied a chain of classifiers for each label.XGBoost and Random Forest produced comparable performance.</p>
<div class="figure">
<img src="Figs/cc_EN_tfidf1.png" />

</div>
<div class="figure">
<img src="Figs/cc_EN_tfidf2.png" />

</div>
</div>
</div>
<div id="language-english-feature-incidence-nr-of-labels-7000-labels" class="section level4 tabset tabset-fade">
<h4><span class="sub-sub-header">Language: English, Feature: Incidence, Nr of Labels: 7000 Labels </span></h4>
<div id="label-powerset-1" class="section level5">
<h5>Label Powerset</h5>
<div class="figure">
<img src="Figs/lp_EN_inc1.png" />

</div>
<div class="figure">
<img src="Figs/lp_EN_inc2.png" />

</div>
</div>
<div id="binary-relevance-1" class="section level5">
<h5>Binary Relevance</h5>
<div class="figure">
<img src="Figs/br_EN_inc1.png" />

</div>
<div class="figure">
<img src="Figs/br_EN_inc2.png" />

</div>
</div>
<div id="classifier-chains-1" class="section level5">
<h5>Classifier Chains</h5>
<div class="figure">
<img src="Figs/cc_EN_inc1.png" />

</div>
<div class="figure">
<img src="Figs/cc_EN_inc2.png" />

</div>
</div>
</div>
<div id="language-german-feature-tf-idf-nr-of-labels-7000-labels" class="section level4 tabset tabset-fade">
<h4><span class="sub-sub-header">Language: German, Feature: TF-IDF, Nr of Labels: 7000 Labels</span></h4>
<div id="label-powerset-2" class="section level5">
<h5>Label Powerset</h5>
</div>
<div id="binary-relevance-2" class="section level5">
<h5>Binary Relevance</h5>
</div>
<div id="classifier-chains-2" class="section level5">
<h5>Classifier Chains</h5>
</div>
</div>
<div id="language-german-feature-incidence-nr-of-labels-7000-labels" class="section level4 tabset tabset-fade">
<h4><span class="sub-sub-header">Language: German, Feature: Incidence, Nr of Labels: 7000 Labels</span></h4>
<div id="label-powerset-3" class="section level5">
<h5>Label Powerset</h5>
<div class="figure">
<img src="Figs/lp_DE_inc1.png" />

</div>
<div class="figure">
<img src="Figs/lp_DE_inc2.png" />

</div>
</div>
<div id="binary-relevance-3" class="section level5">
<h5>Binary Relevance</h5>
<div class="figure">
<img src="Figs/br_DE_inc1.png" />

</div>
<div class="figure">
<img src="Figs/br_DE_inc2.png" />

</div>
</div>
<div id="classifier-chains-3" class="section level5">
<h5>Classifier Chains</h5>
<p>[]](Figs/cc_DE_inc1.png)</p>
<div class="figure">
<img src="Figs/cc_DE_inc2.png" />

</div>
</div>
</div>
<div id="dataset-with-reduced-number-of-labels" class="section level4">
<h4>Dataset with reduced number of labels</h4>
<p>Training our classification models on a dataset with such a large number of labels(7000 labels) is a challenging task. we expected that educing the number of labels would improve the predective capacity of the classifiers. To reduce the large number of labels, we take advangtage of the “scumble” measure provided with the <strong>mldr</strong> package. Scumble measure indicates the concurrence level among frequent and infrequent labels. We removed highly imabalanced label sets by keeping only labelsets with lower level of scumble values than the mean scumble value of the dataset with the following command line:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">datasetWithReducedNrLabels &lt;-<span class="st"> </span>dataset[.SCUMBLE <span class="op">&lt;=</span><span class="st"> </span>dataset<span class="op">$</span>measures<span class="op">$</span>scumble]</code></pre></div>
</div>
<div id="language-english-feature-incidence-nr-of-labels-reduced-number-of-labels" class="section level4 tabset tabset-fade">
<h4><span class="sub-sub-header">Language: English, Feature: Incidence, Nr of Labels: Reduced number of labels</span></h4>
<p>Removing imabalanced labels sets was expected to imporve the performance of the classifiers. However, The classification models maintained similar levels of accuracy rates. Accordingly, we can conclude that the dataset have homogenous label sets, thus the step of removing imbalanced label sets did not have a major impact on the performance.</p>
<div id="label-powerset-4" class="section level5">
<h5>Label Powerset</h5>
<div class="figure">
<img src="Figs/lp_EN_inc1_red.png" />

</div>
<div class="figure">
<img src="Figs/lp_EN_inc2_red.png" />

</div>
</div>
<div id="binary-relevance-4" class="section level5">
<h5>Binary Relevance</h5>
<div class="figure">
<img src="Figs/br_EN_inc1_red.png" />

</div>
<div class="figure">
<img src="Figs/br_EN_inc2_red.png" />

</div>
</div>
<div id="classifier-chain" class="section level5">
<h5>Classifier Chain</h5>
<div class="figure">
<img src="Figs/cc_EN_inc1_red.png" />

</div>
<div class="figure">
<img src="Figs/cc_EN_inc2_red.png" />

</div>
</div>
</div>
<div id="language-english-feature-tf-idf-nr-of-labels-reduced-number-of-labels" class="section level4 tabset tabset-fade">
<h4><span class="sub-sub-header"> Language: English, Feature: TF-IDF, Nr of Labels: Reduced number of labels</span></h4>
<div id="binary-relevance-5" class="section level5">
<h5>Binary Relevance</h5>
<div class="figure">
<img src="Figs/br_EN_tfidf1_red.png" />

</div>
<div class="figure">
<img src="Figs/br_EN_tfidf2_red.png" />

</div>
</div>
<div id="label-powerset-5" class="section level5">
<h5>Label Powerset</h5>
<div class="figure">
<img src="Figs/lp_EN_tfidf1_red.png" />

</div>
<div class="figure">
<img src="Figs/lp_EN_tfidf2_red.png" />

</div>
</div>
</div>
</div>
<div id="conclusion" class="section level3">
<h3>conclusion</h3>
<p>Label powerset method produced generaly the best accuracy compared to the binary relevance methos. Binary relevance method assumes the independecy of labels, on the other hand Label Powerset assumes that coocurring labels in the same instance are correlated, in addition, we have seen that removing the imabalanced label sets did not improve the performance. According to the previous discussion, we present a strong argument that the label sets of the Eur-Lex data set are homogenously distributed.</p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
