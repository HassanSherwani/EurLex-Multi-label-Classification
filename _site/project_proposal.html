<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Team Eur-Lex" />

<meta name="date" content="2018-11-13" />

<title>R Notebook</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>




<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3,h4",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = false;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">My Website</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="process_notebook.html">Multi-label classification</a>
</li>
<li>
  <a href="process_notebook.html">Exploratory Analysis</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">R Notebook</h1>
<h4 class="author"><em>Team Eur-Lex</em></h4>
<h4 class="date"><em>13 November 2018</em></h4>

</div>


<div id="overview-and-motivation" class="section level3">
<h3>Overview and motivation</h3>
<p>A single text document often has multiple semantic aspects. A single news article related to politics may have aspects related to trade, technology and defense. In the perspective of machine learning, we can interpret the various aspects as multiple class labels of an instance (a document). An introduction of enormous amount of documents in the legal domain, makes it an attractive area for employing automated solutions and therefore a machine learning scenario in step with actual practice. In this project we explore a public multi labelled legal text dataset that has been manually annotated over a decade. It contains laws related to the European Union, including treaties, legislation, case-law and legislative proposals, in 22 different languages. This is popularly known as the EUR-Lex dataset containing about twenty thousand documents, around seven thousand labels and in several European languages. A skewed distribution of multiple labels per document, along with existence of the same data in multiple languages, makes this dataset an interesting proposition. Few publications have used an older version of the dataset which had around four thousand labels. The ones that have used this have reported relatively poor values in the range of 50% (which may be fair, given the high number of labels). To the best of our knowledge there has been no publications for the new dataset having around 7000 labels.</p>
</div>
<div id="multilable-classification" class="section level3">
<h3>Multilable classification</h3>
<p>In multi-label classification, each instance in the training set is associated with a set of labels, instead of a single lable, and the task is to predict the <em>label-sets</em> of unseen instances, instead of a single label. There is a difference between <em>multi-class classification</em> and <em>multi-label classification</em>. In multi-class problem the classes or labels are mutually-exclusive, i.e.Â it makes the assumption that each instance can be assigned to only one label. E.g - an animal can be either a dog or a cat but not both.But in multi-label problem multiple labels may be assigned to an instance. E.g - a movie can belong to a comedy genre as well a detective genre.</p>
</div>
<div id="evaluation-meausures" class="section level3">
<h3>Evaluation meausures</h3>
<p>Evaluation measures for a multi-label classification problem needs discussion as it is different from multiclass/binary class problem. In single label classification the commonly used metrics are - accuracy, precision, recall, F1-measure, among others. In multi-label classification we cannot define misclassification as a hard correct or incorrect, but a prediction comprising subset of actual classes is deemed better than containg none of them.</p>
<div id="hamming-loss" class="section level4">
<h4>Hamming Loss</h4>
<p>Hamming Loss is is an example based measure. It is defined as the fraction of labels that are incorrectly predicted.</p>
<p><span class="math inline">\(HL = \frac{1}{N . L} \sum_{l=1}^L\sum_{i=1}^N Y_{i,l} \oplus X_{i,l}\)</span></p>
<p>where denotes exlusive-or, <span class="math inline">\(X_{i,l} (Y_{i,l})\)</span> stands for boolean that the i-th prediction contains the l-th label. For binary scenario (L=1) equals to (1 - accuracy).</p>
</div>
<div id="micro-average-and-macro-average" class="section level4">
<h4>Micro-average and Macro-average</h4>
<p>In order to measure the performance of a multi-class classifier we have to consider the average performance over all classes. There are two different ways of doing this called micro-averaging and macro-averaging. A macro-average will compute the metric independently for each class and then take the average (hence treating all classes equally), whereas a micro-average will aggregate the contributions of all classes to compute the average metric. In a multi-class classification setup, micro-average is preferable if is class imbalance, like our dataset.</p>
<div id="micro-average" class="section level5">
<h5>Micro Average</h5>
<p>In micro all TPs, TNs, FPs and FNs for each class are summed up and then the average is taken. The micro-average F1 is the harmonic mean of the below two equations.</p>
<p><span class="math inline">\(Microaverage Precision Prc^{micro}(D) = \frac{\sum_c TP_c}{\sum_c TP_c + \sum_c FP_c} \)</span></p>
<p><span class="math inline">\(Microaverage Recall Rcl^{micro}(D) = = \frac{\sum_c TP_c}{\sum_c TP_c + \sum_c FN_c} \)</span></p>
</div>
<div id="macro-average" class="section level5">
<h5>Macro Average</h5>
<p>In macro average we take the average of precision and recall of the system on different sets. It is used when we want to know how the algorithm performs overall across different subset of data.</p>
<p><span class="math inline">\(Macrooaverage Precision Prc^{macro}(D) = \frac{\sum_c Prc(D,c)}{|C|} \)</span></p>
<p><span class="math inline">\(Microaverage Recall Rcl^{macro}(D) = \frac{\sum_c Rcl(D,c)}{|C|} \)</span></p>
</div>
</div>
</div>
<div id="work-on-this-dataset" class="section level3">
<h3>work on this dataset</h3>
</div>
<div id="background-and-motivation" class="section level3">
<h3>Background and motivation</h3>
<p>A single text document often has multiple semantic aspects. A single news article related to politics may have aspects related to trade, technology and defense. In the perspective of machine learning, we can interpret the various aspects as multiple class labels of an instance (a document). In this project we explore a public <strong>multi labelled legal</strong> text dataset that has been manually annotated over a decade. It contains laws related to the European Union, including treaties, legislation, case-law and legislative proposals, in 22 different languages. This is popularly known as the <em><strong>EUR-Lex</strong></em> dataset containing about twenty thousand documents and seven thousand labels. A skewed distribution of multiple labels per document, along with existence of the same data in multiple languages, makes this data set an interesting proposition. Few publications have used this dataset; the ones that have used this have reported relatively poor values in the range of 50% (which may be fair, given the high number of labels).</p>
</div>
<div id="project-objectives" class="section level3">
<h3>Project objectives</h3>
<p>In this project we first perform a statistical exploratory analysis of the dataset. Secondly, we plan to experiment the performance of various state-of-the-art classifiers on this dataset. For a better understanding of this classification task, we study the evaluation measures for the multilabel scenario. In the process, we try to answer the following research questions:</p>
<ul>
<li>How well the classifiers perform over Eur-Lex dataset for two languages (English and Deutsch).<br />
</li>
<li>How the classifiersâ performance changes with different features- one with term frequencyÃ¢â¬âinverse document frequency(tf-idf), another with term incidence.<br />
</li>
<li>How the classifiersâ performance changes when the number of labels is reduced</li>
</ul>
</div>
<div id="name-of-dataset" class="section level3">
<h3>Name of dataset:</h3>
<p>European Union law documents (EUR-Lex). The <a href="https://ec.europa.eu/jrc/en/language-technologies/jrc-eurovoc-indexer#Download%20JEX">data</a> is located inside the software distributed by European Union.</p>
</div>
<div id="design-overview-algorithms-and-methods-we-plan-to-use" class="section level3">
<h3>Design overview (algorithms and methods we plan to use)</h3>
<ul>
<li>Statistical exploration :
<ul>
<li>Basic exploration - distribution of attributes/labels</li>
<li>Multi-label specific exploration- labelset distribution, relationship among labels, and relationship between attributes and labels/labelsets</li>
</ul></li>
<li>Pre-processing :
<ul>
<li>Exclude stop words, perform stemming or lemmatization.</li>
<li>Extract features - term frequencyÃ¢â¬âinverse document frequency(tf-idf) and term incidence.</li>
<li>Generate the MLD <span class="citation">[<a href="#ref-Gibaja:2015:TML:2737799.2716262">1</a>]</span> data format, which is needed for multi label data exploration and classification using <em>mldr</em><span class="citation">[<a href="#ref-charte2015working">2</a>]</span> and <em>utiml</em><span class="citation">[<a href="#ref-rivolliutiml">3</a>]</span> packages .</li>
</ul></li>
<li>Apply (atleast) the following classifiers over the preprocessed dataset.
<ul>
<li>IBk (Nearest Neighbour)</li>
<li>RandomForest</li>
<li>SVM</li>
</ul></li>
<li>The following evaluation measures cab be used to assess the multilabel predictive performance:
<ul>
<li>Accuracy</li>
<li>Hamming Loss</li>
<li>Average Precision and Recall</li>
<li>Coverage</li>
<li>Ranking Loss</li>
</ul></li>
<li>Compare the accuracies of the state-of-the-art classifiers on this dataset, for two languages.</li>
</ul>
<div id="references" class="section level4 unnumbered">
<h4>References</h4>
<div id="refs" class="references">
<div id="ref-Gibaja:2015:TML:2737799.2716262">
<p>1. Gibaja E, Ventura S. A tutorial on multilabel learning. ACM Comput Surv. 2015;47:52:1â52:38. doi:<a href="https://doi.org/10.1145/2716262">10.1145/2716262</a>.</p>
</div>
<div id="ref-charte2015working">
<p>2. Charte F, Charte D. Working with multilabel datasets in r: The mldr package. R Journal. 2015;7.</p>
</div>
<div id="ref-rivolliutiml">
<p>3. Rivolli A. Utiml: Utilities for multi-label learning, 2016, r package version 0.1. 0. Available: CRAN R-project org/package= utiml.</p>
</div>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
